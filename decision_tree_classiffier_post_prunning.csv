
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
df=pd.read_csv("decision_tree_classiffier_post_prunning.csv")
x=df[["Income","Age","Score"]].values
y=df["Class"].values
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)
#first we will trauin a tree without any prunning tree grow fuller
model=DecisionTreeClassifier(random_state=42)
model.fit(x_train,y_train)
#finding alphas for model
path=model.cost_complexity_pruning_path(x_train,y_train)
ccp_alphas=path.ccp_alphas
print(ccp_alphas)
#train tree for evvery alpha
best_alpha_accuracy=[]
best_alpha=[]
for i in range(0,len(ccp_alphas),1):
    model1=DecisionTreeClassifier(random_state=42,ccp_alpha=ccp_alphas[i])
    model1.fit(x_train,y_train)
    y_pred=model1.predict(x_test)
    best_alpha_accuracy.append(accuracy_score(y_test,y_pred))
    best_alpha.append(ccp_alphas[i])
if best_alpha_accuracy[0]>best_alpha_accuracy[1]:
    best_alpha=best_alpha[0]
else:
    best_alpha=best_alpha[1]
print(best_alpha,"with accuracy",best_alpha_accuracy[0]*100)

#train final with best alpha
final_model=DecisionTreeClassifier(random_state=42,criterion="entropy",ccp_alpha=best_alpha)
final_model.fit(x_train,y_train)
#alpha jitna incease hoga penalty bhi utni jyada lagegi result tree jyada cut hoga



